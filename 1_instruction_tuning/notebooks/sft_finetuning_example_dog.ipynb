{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Fine-Tuning with SFTTrainer\n",
    "\n",
    "This notebook demonstrates how to fine-tune the `HuggingFaceTB/SmolLM2-135M` model using the `SFTTrainer` from the `trl` library. The notebook cells run and will finetune the model. You can select your difficulty by trying out different datasets.\n",
    "\n",
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
    "    <h2 style='margin: 0;color:blue'>Exercise: Fine-Tuning SmolLM2 with SFTTrainer</h2>\n",
    "    <p>Take a dataset from the Hugging Face hub and finetune a model on it. </p> \n",
    "    <p><b>Difficulty Levels</b></p>\n",
    "    <p>üê¢ Use the `HuggingFaceTB/smoltalk` dataset</p>\n",
    "    <p>üêï Try out the `bigcode/the-stack-smol` dataset and finetune a code generation model on a specific subset `data/python`.</p>\n",
    "    <p>ü¶Å Select a dataset that relates to a real world use case your interested in</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb8e45538034aeaac2cb825e7fd17a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Install the requirements in Google Colab\n",
    "# !pip install transformers datasets trl huggingface_hub\n",
    "\n",
    "# Authenticate to Hugging Face\n",
    "\n",
    "from huggingface_hub import login\n",
    "login()\n",
    "\n",
    "# for convenience you can create an environment variable containing your hub token as HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer, setup_chat_format\n",
    "import torch\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name\n",
    ").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "\n",
    "# Set up the chat format\n",
    "model, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Set our name for the finetune to be saved &/ uploaded to\n",
    "finetune_name = \"SmolLM2-FT-OpenO1-SFT\"\n",
    "finetune_tags = [\"smol-course\", \"module_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate with the base model\n",
    "\n",
    "Here we will try out the base model which does not have a chat template. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n",
      "user\n",
      "Write a Python program that adds two integers\n",
      "Write a Python program that prints the sum of two integers\n",
      "Write a Python program that prints the sum of two integers\n",
      "Write a Python program that prints the sum of two integers\n",
      "Write a Python program that prints the sum of two integers\n",
      "Write a Python program that prints the sum of two integers\n",
      "Write a Python program that prints the sum of two integers\n",
      "Write a Python program that prints the sum of two integers\n",
      "Write a Python program that prints the sum of two integers\n",
      "Write a Python program\n"
     ]
    }
   ],
   "source": [
    "# Let's test the base model before training\n",
    "prompt = \"Write a Python program that adds two integers\"\n",
    "\n",
    "# Format with template\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# Generate response\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "print(\"Before training:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "\n",
    "We will load a sample dataset and format it for training. The dataset should be structured with input-output pairs, where each input is a prompt and the output is the expected response from the model.\n",
    "\n",
    "**TRL will format input messages based on the model's chat templates.** They need to be represented as a list of dictionaries with the keys: `role` and `content`,."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "# TODO: define your dataset and config using the path and name parameters\n",
    "ds = load_dataset(\"O1-OPEN/OpenO1-SFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Create a Python class that encodes a given number using the Full Kocio≈Çek Encryption algorithm. The algorithm should involve multiple stages of mathematical operations and conditional logic. Ensure that the class methods handle all possible edge cases, such as negative numbers, fractions, and large values. Additionally, add a method to decode a number that has been previously encoded using the same algorithm. The decoding method should reverse the mathematical operations performed during encoding and return the original number. The class should also include error handling to handle invalid input and a method to generate a random encryption key for each instance of the class. Finally, write a series of test cases to verify the correctness of the class implementation, covering different types of input and edge cases.', 'output': '<Thought>\\nAlright, I need to create a Python class that implements the Full Kocio≈Çek Encryption algorithm. First, I should understand what this algorithm entails. Since the name doesn\\'t ring a bell, I\\'ll assume it\\'s a fictional or specialized encryption method that involves multiple stages of mathematical operations and conditional logic.\\n\\nStarting off, the class should encode a given number. It needs to handle various edge cases like negative numbers, fractions, and large values. That means I\\'ll have to ensure that the encoding process is robust and doesn\\'t break with unexpected inputs.\\n\\nNext, I need to add a decoding method. This method should reverse the encoding steps precisely to retrieve the original number. To do that, I have to make sure that every mathematical operation in the encoding has an inverse operation in decoding.\\n\\nError handling is crucial. The class should gracefully handle invalid inputs, such as non-numeric values or unsupported data types. Maybe raise appropriate exceptions with clear messages to guide the user.\\n\\nGenerating a random encryption key for each instance adds another layer of complexity. I need to decide how this key influences the encoding and decoding processes. Perhaps it\\'s used as a seed for certain transformations or as a factor in the mathematical operations.\\n\\nWriting test cases is the final step. These should cover a wide range of inputs, including typical use cases and edge cases. I\\'ll include tests for negative numbers, fractions, very large numbers, and invalid inputs to ensure the class behaves as expected in all scenarios.\\n\\nI might start by defining the structure of the class, outlining the necessary methods: `encode`, `decode`, `generate_key`, and maybe an initializer to set up the key. I\\'ll need to decide on the internal representation of the key and how it\\'s stored within the class.\\n\\nFor the encoding algorithm, perhaps I\\'ll implement a series of operations like multiplication, addition, modulo operations, etc., using the key to alter these operations in a way that\\'s reversible. The decoding method will then apply the inverse operations in the reverse order.\\n\\nHandling fractions requires attention. I\\'ll need to decide if the encoding process can handle floating-point numbers directly or if I need to represent fractions in a specific way to maintain precision.\\n\\nFor large values, efficiency might become an issue. I\\'ll consider the computational complexity of the operations involved and optimize where possible to ensure the class performs well even with big numbers.\\n\\nIn terms of error handling, I\\'ll use Python\\'s exception mechanism to catch and respond to invalid inputs. For example, if a user tries to encode a string instead of a number, the class should raise a `TypeError` with a meaningful message.\\n\\nGenerating a random encryption key can be done using Python\\'s `random` module or `secrets` for cryptographic purposes. The key needs to be stored securely within the instance, and perhaps provide a way to reseed or regenerate the key if needed.\\n\\nFor the test cases, I\\'ll use Python\\'s `unittest` framework. I\\'ll write tests for:\\n- Encoding and decoding positive integers\\n- Encoding and decoding negative numbers\\n- Encoding and decoding fractions (floats)\\n- Handling very large numbers\\n- Attempting to encode invalid inputs like strings or `None`\\n- Ensuring that different instances have different keys and that decoding works correctly with the corresponding key\\n\\nThroughout the implementation, I\\'ll document the methods clearly, explaining the purpose and the parameters. This will help users understand how to use the class and what to expect from each method.\\n\\nI might also consider edge cases like encoding zero or handling numbers with a high number of decimal places. Ensuring that the decode method returns the exact original number without loss of precision is important, especially for fractions.\\n\\nFinally, I\\'ll review the code for any potential improvements or optimizations, ensuring that it\\'s clean, efficient, and adheres to Pythonic best practices.\\n\\n</Thought>\\n<Output>\\n```python\\nimport random\\nimport math\\nimport unittest\\n\\nclass FullKociolEncryption:\\n    def __init__(self):\\n        self.key = self.generate_key()\\n    \\n    def generate_key(self):\\n        \"\"\"Generates a random encryption key.\"\"\"\\n        # For demonstration, the key is a tuple of two random integers\\n        key_part1 = random.randint(1000, 9999)\\n        key_part2 = random.randint(1000, 9999)\\n        return (key_part1, key_part2)\\n    \\n    def encode(self, number):\\n        \"\"\"\\n        Encodes the given number using the Full Kocio≈Çek Encryption algorithm.\\n        \\n        Parameters:\\n            number (int, float): The number to encode.\\n        \\n        Returns:\\n            float: The encoded number.\\n        \\n        Raises:\\n            TypeError: If the input is not a number.\\n        \"\"\"\\n        if not isinstance(number, (int, float)):\\n            raise TypeError(\"Input must be an integer or float.\")\\n        \\n        # Handle negative numbers by encoding the absolute value and storing the sign\\n        sign = -1 if number < 0 else 1\\n        abs_number = abs(number)\\n        \\n        # Example encoding steps:\\n        # 1. Multiply by the first part of the key\\n        step1 = abs_number * self.key[0]\\n        \\n        # 2. Add the second part of the key\\n        step2 = step1 + self.key[1]\\n        \\n        # 3. Apply modulo operation to keep the number within a range\\n        step3 = step2 % 1000000  # Arbitrary large number to handle large inputs\\n        \\n        # 4. Take square root to introduce non-linearity\\n        try:\\n            step4 = math.sqrt(step3)\\n        except ValueError:\\n            raise ValueError(\"Invalid operation encountered during encoding.\")\\n        \\n        # 5. Restore the sign\\n        encoded_number = sign * step4\\n        \\n        return encoded_number\\n    \\n    def decode(self, encoded_number):\\n        \"\"\"\\n        Decodes the given encoded number using the Full Kocio≈Çek Encryption algorithm.\\n        \\n        Parameters:\\n            encoded_number (float): The number to decode.\\n        \\n        Returns:\\n            float: The original number.\\n        \\n        Raises:\\n            TypeError: If the input is not a float or int.\\n            ValueError: If decoding fails due to invalid operations.\\n        \"\"\"\\n        if not isinstance(encoded_number, (int, float)):\\n            raise TypeError(\"Encoded input must be an integer or float.\")\\n        \\n        # Handle negative numbers\\n        sign = -1 if encoded_number < 0 else 1\\n        abs_encoded = abs(encoded_number)\\n        \\n        # Example decoding steps (reverse of encoding):\\n        # 1. Square the number to reverse the square root\\n        step1 = abs_encoded ** 2\\n        \\n        # 2. Reverse the modulo operation\\n        # Since modulo was applied, decoding may not retrieve the exact original value\\n        # This is a limitation and would require additional information in a real scenario\\n        step2 = step1  # Placeholder, as reversing modulo is not straightforward\\n        \\n        # 3. Subtract the second part of the key\\n        step3 = step2 - self.key[1]\\n        \\n        # 4. Divide by the first part of the key\\n        if self.key[0] == 0:\\n            raise ZeroDivisionError(\"Invalid key part; division by zero.\")\\n        try:\\n            original_number = step3 / self.key[0]\\n        except Exception as e:\\n            raise ValueError(f\"Decoding failed: {e}\")\\n        \\n        # Restore the original sign\\n        original_number *= sign\\n        \\n        return original_number\\n    \\n    def set_key(self, key):\\n        \"\"\"\\n        Sets a new encryption key.\\n        \\n        Parameters:\\n            key (tuple): A tuple containing two integers.\\n        \\n        Raises:\\n            TypeError: If the key is not a tuple of two integers.\\n        \"\"\"\\n        if (not isinstance(key, tuple)) or (len(key) != 2):\\n            raise TypeError(\"Key must be a tuple of two integers.\")\\n        if not all(isinstance(k, int) for k in key):\\n            raise TypeError(\"Both parts of the key must be integers.\")\\n        self.key = key\\n\\nclass TestFullKociolEncryption(unittest.TestCase):\\n    def setUp(self):\\n        self.encryption = FullKociolEncryption()\\n        self.encryption.set_key((1234, 5678))  # Setting a fixed key for testing\\n    \\n    def test_encode_decode_positive_integer(self):\\n        number = 42\\n        encoded = self.encryption.encode(number)\\n        decoded = self.encryption.decode(encoded)\\n        # Due to modulo and sqrt, exact reverse might not be possible\\n        # Therefore, we check if decoded is close to the original number\\n        self.assertAlmostEqual(decoded, number, places=2)\\n    \\n    def test_encode_decode_negative_integer(self):\\n        number = -100\\n        encoded = self.encryption.encode(number)\\n        decoded = self.encryption.decode(encoded)\\n        self.assertAlmostEqual(decoded, number, places=2)\\n    \\n    def test_encode_decode_fraction(self):\\n        number = 3.14159\\n        encoded = self.encryption.encode(number)\\n        decoded = self.encryption.decode(encoded)\\n        self.assertAlmostEqual(decoded, number, places=2)\\n    \\n    def test_encode_zero(self):\\n        number = 0\\n        encoded = self.encryption.encode(number)\\n        decoded = self.encryption.decode(encoded)\\n        self.assertEqual(decoded, 0)\\n    \\n    def test_encode_large_number(self):\\n        number = 1e12\\n        encoded = self.encryption.encode(number)\\n        decoded = self.encryption.decode(encoded)\\n        self.assertAlmostEqual(decoded, number, places=2)\\n    \\n    def test_encode_invalid_input(self):\\n        with self.assertRaises(TypeError):\\n            self.encryption.encode(\"not a number\")\\n    \\n    def test_decode_invalid_input(self):\\n        with self.assertRaises(TypeError):\\n            self.encryption.decode(\"invalid\")\\n    \\n    def test_decode_zero_division(self):\\n        self.encryption.set_key((0, 5678))\\n        with self.assertRaises(ZeroDivisionError):\\n            self.encryption.decode(100)\\n    \\n    def test_set_invalid_key(self):\\n        with self.assertRaises(TypeError):\\n            self.encryption.set_key(\"invalid key\")\\n        with self.assertRaises(TypeError):\\n            self.encryption.set_key((1234, \"5678\"))\\n        with self.assertRaises(TypeError):\\n            self.encryption.set_key((1234,))\\n    \\n    def test_random_key_uniqueness(self):\\n        keys = set()\\n        for _ in range(100):\\n            encryption_instance = FullKociolEncryption()\\n            keys.add(encryption_instance.key)\\n        self.assertEqual(len(keys), 100, \"Keys are not unique across instances.\")\\n\\nif __name__ == \"__main__\":\\n    unittest.main()\\n```\\n</Output>'}\n"
     ]
    }
   ],
   "source": [
    "print(ds[\"train\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf38128056d49fb87362847e29bc3d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/73800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0541229c44414c8c8af24e30bd7d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3885 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"O1-OPEN/OpenO1-SFT\")\n",
    "\n",
    "\n",
    "ds = ds[\"train\"].train_test_split(test_size=0.05, seed=42)\n",
    "\n",
    "def process_dataset(sample):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": sample[\"instruction\"]},\n",
    "        {\"role\": \"assistant\", \"content\": sample[\"output\"]}\n",
    "    ]\n",
    "    sample[\"chatml\"] = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "    return sample\n",
    "\n",
    "\n",
    "ds = ds.map(process_dataset)\n",
    "# TODO: ü¶Å If your dataset is not in a format that TRL can convert to the chat template, you will need to process it. Refer to the [module](../chat_templates.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the SFTTrainer\n",
    "\n",
    "The `SFTTrainer` is configured with various parameters that control the training process. These include the number of training steps, batch size, learning rate, and evaluation strategy. Adjust these parameters based on your specific requirements and computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['instruction', 'output', 'chatml'],\n",
      "        num_rows: 73800\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['instruction', 'output', 'chatml'],\n",
      "        num_rows: 3885\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/HuaProjects/Tookies/smol-course/.venv/lib/python3.11/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/user/HuaProjects/Tookies/smol-course/.venv/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "# Configure the SFTTrainer\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=\"./sft_output\",\n",
    "    max_steps=1000,  # Adjust based on dataset size and desired training duration\n",
    "    per_device_train_batch_size=1,  # Set according to your GPU memory capacity\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=5e-5,  # Common starting point for fine-tuning\n",
    "    logging_steps=10,  # Frequency of logging training metrics\n",
    "    save_steps=100,  # Frequency of saving model checkpoints\n",
    "    evaluation_strategy=\"steps\",  # Evaluate the model at regular intervals\n",
    "    eval_steps=50,  # Frequency of evaluation\n",
    "    use_mps_device=(\n",
    "        True if device == \"mps\" else False\n",
    "    ),  # Use MPS for mixed precision training\n",
    "    hub_model_id=finetune_name,  # Set a unique name for your model\n",
    "    dataset_text_field=\"chatml\",\n",
    ")\n",
    "\n",
    "# Initialize the SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=sft_config,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    tokenizer=tokenizer,\n",
    "    eval_dataset=ds[\"test\"],\n",
    ")\n",
    "\n",
    "# TODO: ü¶Å üêï align the SFTTrainer params with your chosen dataset. For example, if you are using the `bigcode/the-stack-smol` dataset, you will need to choose the `content` column`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "With the trainer configured, we can now proceed to train the model. The training process will involve iterating over the dataset, computing the loss, and updating the model's parameters to minimize this loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40ccd621eab4e85afbdc8dc0fa5a6f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.689, 'grad_norm': 4.789322376251221, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.0}\n",
      "{'loss': 1.6809, 'grad_norm': 2.5645437240600586, 'learning_rate': 4.9e-05, 'epoch': 0.0}\n",
      "{'loss': 1.4344, 'grad_norm': 1.8341213464736938, 'learning_rate': 4.85e-05, 'epoch': 0.0}\n",
      "{'loss': 1.6071, 'grad_norm': 2.0909006595611572, 'learning_rate': 4.8e-05, 'epoch': 0.0}\n",
      "{'loss': 1.3541, 'grad_norm': 2.3180649280548096, 'learning_rate': 4.75e-05, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67299a67b33459abb62c65d719a7c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.453147530555725, 'eval_runtime': 92.1703, 'eval_samples_per_second': 42.15, 'eval_steps_per_second': 5.273, 'epoch': 0.0}\n",
      "{'loss': 1.4948, 'grad_norm': 2.5666050910949707, 'learning_rate': 4.7e-05, 'epoch': 0.0}\n",
      "{'loss': 1.591, 'grad_norm': 2.4415390491485596, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.0}\n",
      "{'loss': 1.5125, 'grad_norm': 2.3992252349853516, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.0}\n",
      "{'loss': 1.4225, 'grad_norm': 2.355292320251465, 'learning_rate': 4.55e-05, 'epoch': 0.0}\n",
      "{'loss': 1.4036, 'grad_norm': 2.748029947280884, 'learning_rate': 4.5e-05, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38146970a91648738f0a470089ceb95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4245418310165405, 'eval_runtime': 91.7127, 'eval_samples_per_second': 42.361, 'eval_steps_per_second': 5.299, 'epoch': 0.0}\n",
      "{'loss': 1.4195, 'grad_norm': 2.51503849029541, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.0}\n",
      "{'loss': 1.5014, 'grad_norm': 2.0570900440216064, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.0}\n",
      "{'loss': 1.4052, 'grad_norm': 2.3576667308807373, 'learning_rate': 4.35e-05, 'epoch': 0.0}\n",
      "{'loss': 1.3767, 'grad_norm': 2.480306386947632, 'learning_rate': 4.3e-05, 'epoch': 0.0}\n",
      "{'loss': 1.2872, 'grad_norm': 1.799786925315857, 'learning_rate': 4.25e-05, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297b24ad67e941f883310feff5a2e022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.409893274307251, 'eval_runtime': 90.4584, 'eval_samples_per_second': 42.948, 'eval_steps_per_second': 5.373, 'epoch': 0.0}\n",
      "{'loss': 1.3611, 'grad_norm': 3.009833335876465, 'learning_rate': 4.2e-05, 'epoch': 0.0}\n",
      "{'loss': 1.342, 'grad_norm': 1.8054674863815308, 'learning_rate': 4.15e-05, 'epoch': 0.0}\n",
      "{'loss': 1.2738, 'grad_norm': 2.289461135864258, 'learning_rate': 4.1e-05, 'epoch': 0.0}\n",
      "{'loss': 1.2882, 'grad_norm': 2.8470284938812256, 'learning_rate': 4.05e-05, 'epoch': 0.0}\n",
      "{'loss': 1.5645, 'grad_norm': 2.3178188800811768, 'learning_rate': 4e-05, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3c673423c045bea01159288098262b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4000062942504883, 'eval_runtime': 90.7513, 'eval_samples_per_second': 42.809, 'eval_steps_per_second': 5.355, 'epoch': 0.0}\n",
      "{'loss': 1.3772, 'grad_norm': 2.395841598510742, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.0}\n",
      "{'loss': 1.3767, 'grad_norm': 1.9965555667877197, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.0}\n",
      "{'loss': 1.3301, 'grad_norm': 1.7246627807617188, 'learning_rate': 3.85e-05, 'epoch': 0.0}\n",
      "{'loss': 1.2738, 'grad_norm': 2.046168088912964, 'learning_rate': 3.8e-05, 'epoch': 0.0}\n",
      "{'loss': 1.3679, 'grad_norm': 2.202080726623535, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb8774f9ffd414d8c35e3ed58162a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3930296897888184, 'eval_runtime': 90.5558, 'eval_samples_per_second': 42.902, 'eval_steps_per_second': 5.367, 'epoch': 0.0}\n",
      "{'loss': 1.4223, 'grad_norm': 1.7117208242416382, 'learning_rate': 3.7e-05, 'epoch': 0.0}\n",
      "{'loss': 1.4019, 'grad_norm': 1.853203535079956, 'learning_rate': 3.65e-05, 'epoch': 0.0}\n",
      "{'loss': 1.5983, 'grad_norm': 2.0216317176818848, 'learning_rate': 3.6e-05, 'epoch': 0.0}\n",
      "{'loss': 1.2374, 'grad_norm': 2.044203519821167, 'learning_rate': 3.55e-05, 'epoch': 0.0}\n",
      "{'loss': 1.1863, 'grad_norm': 2.3213438987731934, 'learning_rate': 3.5e-05, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf17b3fc2174d45962bb9a2369c74ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3855910301208496, 'eval_runtime': 90.78, 'eval_samples_per_second': 42.796, 'eval_steps_per_second': 5.354, 'epoch': 0.0}\n",
      "{'loss': 1.3697, 'grad_norm': 2.024261474609375, 'learning_rate': 3.45e-05, 'epoch': 0.0}\n",
      "{'loss': 1.1557, 'grad_norm': 1.9779845476150513, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.0}\n",
      "{'loss': 1.1995, 'grad_norm': 1.6118735074996948, 'learning_rate': 3.35e-05, 'epoch': 0.0}\n",
      "{'loss': 1.3648, 'grad_norm': 2.4329745769500732, 'learning_rate': 3.3e-05, 'epoch': 0.0}\n",
      "{'loss': 1.4938, 'grad_norm': 2.9569737911224365, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc4662df944415ba590509170509be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3809256553649902, 'eval_runtime': 90.5066, 'eval_samples_per_second': 42.925, 'eval_steps_per_second': 5.37, 'epoch': 0.0}\n",
      "{'loss': 1.4809, 'grad_norm': 1.954123616218567, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.0}\n",
      "{'loss': 1.4009, 'grad_norm': 2.5831949710845947, 'learning_rate': 3.15e-05, 'epoch': 0.01}\n",
      "{'loss': 1.3681, 'grad_norm': 1.8824050426483154, 'learning_rate': 3.1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.7052, 'grad_norm': 2.349090099334717, 'learning_rate': 3.05e-05, 'epoch': 0.01}\n",
      "{'loss': 1.3682, 'grad_norm': 2.7711987495422363, 'learning_rate': 3e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af808ceb9cc143c3ba6d26f51a29fe5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3754383325576782, 'eval_runtime': 90.6954, 'eval_samples_per_second': 42.836, 'eval_steps_per_second': 5.359, 'epoch': 0.01}\n",
      "{'loss': 1.2365, 'grad_norm': 1.8296515941619873, 'learning_rate': 2.95e-05, 'epoch': 0.01}\n",
      "{'loss': 1.2945, 'grad_norm': 1.848389744758606, 'learning_rate': 2.9e-05, 'epoch': 0.01}\n",
      "{'loss': 1.5328, 'grad_norm': 4.201485633850098, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.01}\n",
      "{'loss': 1.3453, 'grad_norm': 1.994139313697815, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.01}\n",
      "{'loss': 1.2874, 'grad_norm': 1.9883641004562378, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25385f588bdc45e39bc192b87db4d18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3711432218551636, 'eval_runtime': 90.5493, 'eval_samples_per_second': 42.905, 'eval_steps_per_second': 5.367, 'epoch': 0.01}\n",
      "{'loss': 1.2253, 'grad_norm': 1.980276346206665, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.01}\n",
      "{'loss': 1.4719, 'grad_norm': 1.8294522762298584, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.01}\n",
      "{'loss': 1.2042, 'grad_norm': 1.9215508699417114, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.01}\n",
      "{'loss': 1.2926, 'grad_norm': 2.4596991539001465, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.01}\n",
      "{'loss': 1.3033, 'grad_norm': 2.0537326335906982, 'learning_rate': 2.5e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1047a729fda6479684566b9893064d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3673151731491089, 'eval_runtime': 90.488, 'eval_samples_per_second': 42.934, 'eval_steps_per_second': 5.371, 'epoch': 0.01}\n",
      "{'loss': 1.5142, 'grad_norm': 2.9137418270111084, 'learning_rate': 2.45e-05, 'epoch': 0.01}\n",
      "{'loss': 1.4467, 'grad_norm': 2.355863571166992, 'learning_rate': 2.4e-05, 'epoch': 0.01}\n",
      "{'loss': 1.4542, 'grad_norm': 2.123986005783081, 'learning_rate': 2.35e-05, 'epoch': 0.01}\n",
      "{'loss': 1.337, 'grad_norm': 2.521394729614258, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.01}\n",
      "{'loss': 1.3946, 'grad_norm': 2.3617360591888428, 'learning_rate': 2.25e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ef426c282e4404adc1daf9480a19ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3631824254989624, 'eval_runtime': 90.6694, 'eval_samples_per_second': 42.848, 'eval_steps_per_second': 5.36, 'epoch': 0.01}\n",
      "{'loss': 1.3036, 'grad_norm': 1.919806718826294, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.01}\n",
      "{'loss': 1.3541, 'grad_norm': 2.847322940826416, 'learning_rate': 2.15e-05, 'epoch': 0.01}\n",
      "{'loss': 1.1123, 'grad_norm': 2.0737547874450684, 'learning_rate': 2.1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.207, 'grad_norm': 1.6252124309539795, 'learning_rate': 2.05e-05, 'epoch': 0.01}\n",
      "{'loss': 1.217, 'grad_norm': 2.1085684299468994, 'learning_rate': 2e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bceaed96b6a44768a41f563bca22ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3600345849990845, 'eval_runtime': 92.9108, 'eval_samples_per_second': 41.814, 'eval_steps_per_second': 5.231, 'epoch': 0.01}\n",
      "{'loss': 1.3624, 'grad_norm': 2.3510632514953613, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.01}\n",
      "{'loss': 1.3743, 'grad_norm': 2.1926167011260986, 'learning_rate': 1.9e-05, 'epoch': 0.01}\n",
      "{'loss': 1.1431, 'grad_norm': 1.862229585647583, 'learning_rate': 1.85e-05, 'epoch': 0.01}\n",
      "{'loss': 1.2535, 'grad_norm': 2.032979726791382, 'learning_rate': 1.8e-05, 'epoch': 0.01}\n",
      "{'loss': 1.2052, 'grad_norm': 2.216193675994873, 'learning_rate': 1.75e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee4683aefb0442d8485c1349f132f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.356460690498352, 'eval_runtime': 93.8557, 'eval_samples_per_second': 41.393, 'eval_steps_per_second': 5.178, 'epoch': 0.01}\n",
      "{'loss': 1.1476, 'grad_norm': 2.0505435466766357, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.01}\n",
      "{'loss': 1.524, 'grad_norm': 1.8408827781677246, 'learning_rate': 1.65e-05, 'epoch': 0.01}\n",
      "{'loss': 1.289, 'grad_norm': 2.4589998722076416, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.01}\n",
      "{'loss': 1.343, 'grad_norm': 2.056774616241455, 'learning_rate': 1.55e-05, 'epoch': 0.01}\n",
      "{'loss': 1.3168, 'grad_norm': 1.8761483430862427, 'learning_rate': 1.5e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098882aa52d24b74b2629d555f433bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.354556918144226, 'eval_runtime': 92.5692, 'eval_samples_per_second': 41.969, 'eval_steps_per_second': 5.25, 'epoch': 0.01}\n",
      "{'loss': 1.3702, 'grad_norm': 2.1866226196289062, 'learning_rate': 1.45e-05, 'epoch': 0.01}\n",
      "{'loss': 1.3251, 'grad_norm': 1.9183235168457031, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 1.1688, 'grad_norm': 1.9891434907913208, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 1.4208, 'grad_norm': 2.2401413917541504, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 1.4554, 'grad_norm': 2.0122013092041016, 'learning_rate': 1.25e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da2679ade4741699111008f364049d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3514670133590698, 'eval_runtime': 93.0476, 'eval_samples_per_second': 41.753, 'eval_steps_per_second': 5.223, 'epoch': 0.01}\n",
      "{'loss': 1.3481, 'grad_norm': 3.1469266414642334, 'learning_rate': 1.2e-05, 'epoch': 0.01}\n",
      "{'loss': 1.5123, 'grad_norm': 2.2107110023498535, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.01}\n",
      "{'loss': 1.1797, 'grad_norm': 1.7923365831375122, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 1.2285, 'grad_norm': 1.9447473287582397, 'learning_rate': 1.05e-05, 'epoch': 0.01}\n",
      "{'loss': 1.3115, 'grad_norm': 2.3494105339050293, 'learning_rate': 1e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b48f8ecaf164ac1bb284dfe308d8d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3495628833770752, 'eval_runtime': 93.8749, 'eval_samples_per_second': 41.385, 'eval_steps_per_second': 5.177, 'epoch': 0.01}\n",
      "{'loss': 1.1884, 'grad_norm': 1.8228445053100586, 'learning_rate': 9.5e-06, 'epoch': 0.01}\n",
      "{'loss': 1.3492, 'grad_norm': 1.9050586223602295, 'learning_rate': 9e-06, 'epoch': 0.01}\n",
      "{'loss': 1.1718, 'grad_norm': 2.0664191246032715, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.01}\n",
      "{'loss': 1.4601, 'grad_norm': 1.613179326057434, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 1.5466, 'grad_norm': 2.0918474197387695, 'learning_rate': 7.5e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c915705a50648a398090ee6481701a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.347545862197876, 'eval_runtime': 92.8362, 'eval_samples_per_second': 41.848, 'eval_steps_per_second': 5.235, 'epoch': 0.01}\n",
      "{'loss': 1.2692, 'grad_norm': 1.8502833843231201, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 1.4031, 'grad_norm': 1.8780512809753418, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.01}\n",
      "{'loss': 1.4512, 'grad_norm': 2.0847387313842773, 'learning_rate': 6e-06, 'epoch': 0.01}\n",
      "{'loss': 1.1578, 'grad_norm': 2.1720614433288574, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 1.2733, 'grad_norm': 2.041264057159424, 'learning_rate': 5e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af00e7d61a3c46129a9db5d5e992a1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.346459150314331, 'eval_runtime': 93.8329, 'eval_samples_per_second': 41.403, 'eval_steps_per_second': 5.179, 'epoch': 0.01}\n",
      "{'loss': 1.344, 'grad_norm': 2.1930482387542725, 'learning_rate': 4.5e-06, 'epoch': 0.01}\n",
      "{'loss': 1.2041, 'grad_norm': 1.9583771228790283, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 1.604, 'grad_norm': 2.241290807723999, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.01}\n",
      "{'loss': 1.2927, 'grad_norm': 2.1759748458862305, 'learning_rate': 3e-06, 'epoch': 0.01}\n",
      "{'loss': 1.4155, 'grad_norm': 1.7820384502410889, 'learning_rate': 2.5e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987f6c9de6ae4de58baa82aad8ff4976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.345608115196228, 'eval_runtime': 93.2482, 'eval_samples_per_second': 41.663, 'eval_steps_per_second': 5.212, 'epoch': 0.01}\n",
      "{'loss': 1.2435, 'grad_norm': 2.1484668254852295, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.01}\n",
      "{'loss': 1.5263, 'grad_norm': 1.6413675546646118, 'learning_rate': 1.5e-06, 'epoch': 0.01}\n",
      "{'loss': 1.3848, 'grad_norm': 2.2584738731384277, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.01}\n",
      "{'loss': 1.3049, 'grad_norm': 2.09061336517334, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.01}\n",
      "{'loss': 1.333, 'grad_norm': 2.1181726455688477, 'learning_rate': 0.0, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6f1b2b37ce46198cd1e4bcc57e2e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3451868295669556, 'eval_runtime': 93.4894, 'eval_samples_per_second': 41.555, 'eval_steps_per_second': 5.198, 'epoch': 0.01}\n",
      "{'train_runtime': 1966.3726, 'train_samples_per_second': 0.509, 'train_steps_per_second': 0.509, 'train_loss': 1.3622560482025146, 'epoch': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the model\n",
    "trainer.save_model(f\"./{finetune_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8e4606450b49f4a79f528f3dd884e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27fbf14b93bd479497c6028acda4e3bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/538M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7046cf65abe642f59092bb481413eae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Tookies/SmolLM2-FT-OpenO1-SFT/commit/b9b0bc9d1581565ea390a7940405b211d7de1453', commit_message='End of training', commit_description='', oid='b9b0bc9d1581565ea390a7940405b211d7de1453', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Tookies/SmolLM2-FT-OpenO1-SFT', endpoint='https://huggingface.co', repo_type='model', repo_id='Tookies/SmolLM2-FT-OpenO1-SFT'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(tags=finetune_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
    "    <h2 style='margin: 0;color:blue'>Bonus Exercise: Generate with fine-tuned model</h2>\n",
    "    <p>üêï Use the fine-tuned to model generate a response, just like with the base example..</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training:\n",
      "user\n",
      "Write a Python program that adds two integers\n",
      "assistant\n",
      "<Thought>\n",
      "Alright, I need to write a Python program that adds two integers. Let's break this down step by step.\n",
      "\n",
      "First, I should consider the input format. The program should accept two integers as input. The first integer should be the first integer, and the second integer should be the second integer.\n",
      "\n",
      "Next, I need to handle the comparison between the two integers. If the first integer is greater than the second, I should return `True`. If the first integer is less than the second, I should return `False`.\n",
      "\n",
      "I should also consider edge cases. For example, what if the first integer is zero? In that case, the program should return `False`. What if the first integer is negative? In that case, the program should return `False`. What if the first integer is zero and the second integer is negative? In that case, the program should return `False`.\n",
      "\n",
      "Also, I need to handle the case where the first integer is zero and the second integer is negative. In that case, the program should return `False`.\n",
      "\n",
      "I should also think about the output format. The program should display the result of the addition. If the first integer is zero, the program should display a message indicating that the addition is successful. If the second integer is zero, the program should display a message indicating that the addition is successful.\n",
      "\n",
      "I should also think about the time complexity. The program should run in O(1) time, which means it doesn't need to check if the first integer is zero or not.\n",
      "\n",
      "I should also think about the memory usage. The program should allocate memory for the integers, and it should allocate memory for the result. The program should also allocate memory for the result itself.\n",
      "\n",
      "I should also consider the input validation. The program should validate the input. For example, if the first integer is zero, the program should display a message indicating that the addition is successful. If the second integer is zero, the program should display a message indicating that the addition is successful.\n",
      "\n",
      "I should also think about the error handling. The program should handle any exceptions that might occur during the addition. For example, if the first integer is zero, the program should display a message indicating that the addition is successful. If the second integer is zero, the program should display a message indicating that the addition is successful.\n",
      "\n",
      "I should also think about the performance. The program should run in O(1) time, which means it doesn't need to check if the first integer is zero or not.\n",
      "\n",
      "I should also consider the input validation. The program should validate the input. For example, if the first integer is zero, the program should display a message indicating that the addition is successful. If the second integer is zero, the program should display a message indicating that the addition is successful.\n",
      "\n",
      "I should also think about the output format. The program should display the result of the addition. If the first integer is zero, the program should display a message indicating that the addition is successful. If the second integer is zero, the program should display a message indicating that the addition is successful.\n",
      "\n",
      "I should also think about the error handling. The program should handle any exceptions that might occur during the addition. For example, if the first integer is zero, the program should display a message indicating that the addition is successful. If the second integer is zero, the program should display a message indicating that the addition is successful.\n",
      "\n",
      "I should also think about the time complexity. The program should run in O(1) time, which means it doesn't need to check if the first integer is zero or not.\n",
      "\n",
      "I should also think about the memory usage. The program should allocate memory for the result. For example, if the first integer is zero, the program should allocate memory for the result. For example, if the first integer is zero, the program should allocate memory for the result.\n",
      "\n",
      "I should also think about the input validation. The program should validate the input. For example, if the first integer is zero, the program should display a message indicating that the addition is successful. If the second integer is zero, the program should display a message indicating that the addition is successful.\n",
      "\n",
      "I should also think about the error handling. The program should handle any exceptions that might occur during the addition. For example, if the first integer is zero, the program should display a message indicating that the addition is successful. If the second integer is zero, the program should display a message indicating that the addition is successful.\n",
      "\n",
      "I should also think about the time complexity. The program should run in O(1) time, which means it doesn't need to check if the first integer is zero or not.\n",
      "\n",
      "I should also think about the error handling. The program should handle any exceptions that might occur during the addition. For example, if the first integer is zero, the program should display a message indicating that the addition is successful. If the second integer is zero, the program should display a message indicating that the addition is successful.\n",
      "\n",
      "I should also think about the time complexity. The program should run in O(1) time, which means it doesn't need to check if the first integer is zero or not.\n",
      "\n",
      "I should also think about the memory usage. The program should allocate memory for the result. For example, if the first integer is zero, the program should allocate memory for the result. For example, if the first integer is zero, the program should allocate memory for the result. For example, if the first integer is zero, the program should allocate memory for the result.\n",
      "\n",
      "I should also think about the input validation. The program should validate the input. For example, if the first integer is zero, the program should display a message indicating that the addition is successful. If the second integer is zero, the program should display a message indicating that the addition is successful.\n",
      "\n",
      "I should also think about the error handling. The program should handle any exceptions that might occur during the addition. For example, if the first integer is zero, the program should display a message indicating that the addition is successful. If the second integer is zero, the program should display a message indicating that the addition is successful.\n",
      "\n",
      "I should also think about the time complexity. The program should run in O(1) time, which means it doesn't need to check if the first integer is zero or not.\n",
      "\n",
      "I should also think about the memory usage. The program should allocate memory for the result. For example, if the first integer is zero, the program should allocate memory for the result. For example, if the first integer is zero, the program should allocate memory for the result. For example, if the first integer is zero, the program should allocate memory for the result. For example, if the first integer is zero, the program should allocate memory for the result.\n",
      "\n",
      "I should also think about the input validation. The program should validate the input. For example, if the first integer is zero, the program should display a message indicating that the addition is successful. If the second integer is zero, the program should display a message indicating that the addition is successful.\n",
      "\n",
      "I should also think about the\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model on the same prompt\n",
    "\n",
    "# Let's test the base model before training\n",
    "prompt = \"Write a Python program that adds two integers\"\n",
    "\n",
    "# Format with template\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# Generate response\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# TODO: use the fine-tuned to model generate a response, just like with the base example.\n",
    "outputs = model.generate(**inputs, max_new_tokens=1500)\n",
    "print(\"After training:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training:\n",
      "user\n",
      "Write a haiku about programming\n",
      "assistant\n",
      "<Thought>\n",
      "Alright, I need to write a haiku about programming. Let's start by understanding what programming is. Programming is the process of writing code to solve problems or perform tasks. It involves using programming languages like Python, Java, or C++ to create software applications.\n",
      "\n",
      "Now, programming is a broad field, and there are many different programming languages. Python is a popular choice because of its simplicity and powerful features. Java is another option, but I'll stick with Python for simplicity.\n",
      "\n",
      "So, I'll need to choose a programming language that's easy to learn and understand. Python is a good choice because it's a general-purpose programming language that's easy to learn and use.\n",
      "\n",
      "Next, I'll think about the programming language's structure. Python is a dynamically typed language, which means it's not tied to a specific type of data. This makes it more flexible and adaptable.\n",
      "\n",
      "I'll also consider the programming language's syntax. Python is a simple language, so it's easy to read and write. Java is more structured, so it's more readable.\n",
      "\n",
      "I'll also think about the programming language's libraries. Libraries are pre-written code that can be used in place of the language's built-in functions. Python has a large library of built-in functions, so I'll need to choose a library that's appropriate for the programming language.\n",
      "\n",
      "I'll also think about the programming language's documentation. Python has a vast documentation, so I'll need to choose a documentation that's clear and easy to understand.\n",
      "\n",
      "I'll also consider the programming language's community. Python is widely used, so I'll need to choose a community that supports Python. I'll need to choose a community that's active and supportive of Python.\n",
      "\n",
      "I'll also think about the programming language's community. Python is a community, so I'll need to choose a community that's active and supportive of Python. I'll need to choose a community that's active and supportive of Python.\n",
      "\n",
      "I'll also think about the programming language's community's community. Python is a community, so I'll need to choose a community that's active and supportive of Python. I'll need to choose a community that's active and supportive of Python.\n",
      "\n",
      "I'll also think about the programming language's community's community's community. Python is a community, so I'll need to choose a community\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model on the same prompt\n",
    "\n",
    "# Let's test the base model before training\n",
    "prompt = \"Write a haiku about programming\"\n",
    "\n",
    "# Format with template\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# Generate response\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# TODO: use the fine-tuned to model generate a response, just like with the base example.\n",
    "outputs = model.generate(**inputs, max_new_tokens=500)\n",
    "print(\"After training:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Kernel will shut down...</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<h2>Kernel will shut down...</h2>\"))\n",
    "\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíê You're done!\n",
    "\n",
    "This notebook provided a step-by-step guide to fine-tuning the `HuggingFaceTB/SmolLM2-135M` model using the `SFTTrainer`. By following these steps, you can adapt the model to perform specific tasks more effectively. If you want to carry on working on this course, here are steps you could try out:\n",
    "\n",
    "- Try this notebook on a harder difficulty\n",
    "- Review a colleagues PR\n",
    "- Improve the course material via an Issue or PR."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
